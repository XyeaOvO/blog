请你在experiments/下新建一个文件夹，开发一个WebUI项目，需求如下：
### 1. 数据输入
*   **功能**：用户在 Web 界面输入服务器端文件路径打开obj模型文件如（models/House3K_obj/BATCH_1/Set_A/BAT1_SETA_HOUSE1.obj）。

### 2. 3D 交互与预览模块
*   **功能**：一个实时的 3D 画布。
*   **操作 A (查看)**：用户可以拖拽鼠标，旋转、缩放模型，从不同角度观察模型细节。
*   **操作 B (放置相机)**：用户旋转到某个视角，觉得“这个角度不错”，就把**当前的屏幕视角位置（xyz)** 作为新增的一个渲染相机的位置(xyz)加到相机列表里。相机旋转朝向调用lookat计算，参考nbv_framework/datasets/house3k_dataset.py 的_build_camera_poses。

### 3. 核心计算触发模块
*   **操作**：界面右下角有一个按钮，比如“计算 / Calculate”。
*   **触发动作**：点击后，前端将当前的 **相机列表的所有相机的参数** 发送给后端。

### 4. 后端计算模块
后端接收到相机参数后，执行流水线：
1.  **加载模型**：读取上传的 OBJ。
2.  **微分渲染 (Render)**：使用 nbv_framework/rendering/differentiable_renderer.py，渲染出RGB图和点云图。
3.  **GT点云采样**：使用 ‘nbv_framework/utils/mesh_utils.py’从 Mesh 表面采样得到点云，参数默认即可。
4.  **计算 Loss (Chamfer Distance)**：
    参考nbv_framework/training/trainer.py中build_recon_from_point_maps和计算loss的方式，直接调用计算

### 5. 结果展示与历史记录 (Result & State Management)
*   **功能**：计算完成后，不覆盖当前界面，而是生成一条记录，同时展现在前端和保存到本地。
*   **展示内容**：
    *   渲染出来的 **2D 相机图**和**点云图**。
    *   计算出的 **Chamfer Distance Loss 数值**。
*   **状态保存**：可以多次点击，生成列表，方便对比不同视角组合下的渲染效果和 Loss 变化。
### 6.技术要求
- 不得修改现有的代码
- 自拟技术框架，搭建环境
- 交付时候给我一个readme
---
