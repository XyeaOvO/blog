(unifolm-wma) root@autodl-container-jr13femtww-62b5cc0c:~/unifolm-world-model-action#  WMA_PROFILE_INIT=1 WMA_PROFILE_INSTANTIATE=1 bash unitree_g1_pack_camera/case1/run_world_model_interaction.sh
/root/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
Global seed set to 123
[init-prof] enabled
[init-prof] load config: 0.027s
[instantiate]         unifolm_wma.models.diffusion_head.vision.model_getter.get_resnet 0.101s
[instantiate]       unifolm_wma.models.diffusion_head.vision.multi_image_obs_encoder.MultiImageObsEncoder 0.153s
[instantiate]     unifolm_wma.models.diffusion_head.conditional_unet1d.ConditionalUnet1D 2.411s
[instantiate]         unifolm_wma.models.diffusion_head.vision.model_getter.get_resnet 0.098s
[instantiate]       unifolm_wma.models.diffusion_head.vision.multi_image_obs_encoder.MultiImageObsEncoder 0.131s
[instantiate]     unifolm_wma.models.diffusion_head.conditional_unet1d.ConditionalUnet1D 2.352s
[instantiate]     unifolm_wma.modules.encoders.condition.SATokenProjector 0.066s
[instantiate]   unifolm_wma.modules.networks.wma_model.WMAModel 12.320s
AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.
[instantiate]     torch.nn.Identity 0.000s
[instantiate]   unifolm_wma.models.autoencoder.AutoencoderKL 0.389s
[instantiate]   unifolm_wma.modules.encoders.condition.FrozenOpenCLIPEmbedder 6.763s
[instantiate]   unifolm_wma.modules.encoders.condition.FrozenOpenCLIPImageEmbedderV2 6.452s
[instantiate]   unifolm_wma.modules.encoders.resampler.Resampler 0.244s
[instantiate]   diffusers.DDIMScheduler 0.004s
[instantiate]   diffusers.DDIMScheduler 0.001s
[instantiate] unifolm_wma.models.ddpms.LatentVisualDiffusion 27.205s
[init-prof] instantiate model: 27.209s
>>> model checkpoint loaded.
[init-prof] load model checkpoint: 12.599s
>>> Loaded pre-trained model ...
[instantiate] unifolm_wma.utils.data.DataModuleFromConfig 0.001s
[init-prof] instantiate data: 0.001s
>>> unitree_g1_pack_camera: 1 data samples loaded.
>>> unitree_g1_pack_camera: data stats loaded.
>>> unitree_g1_pack_camera: normalizer initiated.
[instantiate] unifolm_wma.data.wma_data.WMAData 0.331s
[init-prof] data setup: 0.331s
>>> Dataset is successfully loaded ...
[init-prof] model to cuda: 4.026s
[init-prof] torch.compile: 1.058s
[init-prof] build sampler: 0.000s
>>> Generate 16 frames under each generation ...