# 基于全连接神经网络的CIFAR-10图像分类实验报告
<center> <div style='height:2mm;'> </div> <div style="font-family:华文楷体;font-size:14pt;">未来学院 2023217804班陈墨涵 2023212641</div> </center>

---

#### **摘要**

本项目旨在设计并实现一个用于CIFAR-10图像分类的全连接神经网络。我们系统性地探索了不同网络架构、损失函数、正则化方法以及优化算法对模型性能的影响。通过使用 Weights & Biases 工具进行高效的贝叶斯超参数搜索与Hyperband早停，我们确定了一组最优配置。最终，我们的最佳模型在CIFAR-10测试集上达到了 **70.16%** 的准确率。实验结果表明，一个兼具宽度与深度的网络架构 (1024, 1024, 512) 是有效学习特征的关键；其次，AdamW优化器与Cosine退火学习率调度器的组合在收敛速度和最终性能上表现最佳；最后，适度的Dropout (~0.3) 是平衡大型模型表达能力与泛化性能最重要的正则化手段。

---

### **1. 引言**

#### **1.1 任务背景**
图像分类是计算机视觉领域的一项基础且核心的任务。本次作业要求我使用经典的全连接神经网络（Fully Connected Neural Network, FCN）对CIFAR-10数据集进行分类。CIFAR-10数据集包含了10个类别的60000张32x32的彩色图像，是一个广泛用于评测图像分类算法性能的基准数据集。

#### **1.2 实验目标**
本实验的主要目标包括：
*   理解并搭建一个完整的图像分类流程，包括数据预处理、模型设计、训练与评估。
*   掌握通过验证集调整超参数的方法，理解训练集、验证集和测试集的划分意义。
*   （附加任务）探究不同损失函数（如交叉熵、Focal Loss）和正则化方法（如Dropout、权重衰减）对模型性能及泛化能力的影响。
*   （附加任务）对比分析不同优化算法（如SGD, AdamW）及学习率调度策略（如Plateau, Cosine）对模型训练过程和最终性能的影响。

---

### **2. 实验设计**

#### **2.1 数据集**
*   **数据集**: CIFAR-10
*   **图像尺寸**: 3x32x32
*   **类别数量**: 10
*   **数据划分**: 训练集50000张，测试集10000张。在训练过程中，我将原始训练集进一步划分为训练集（40000张）和验证集（10000张），用于模型选择和超参数调整。
*   **数据增强**: 仅仅使用原始训练集，模型很可能会学到一些与特定图像强相关的“捷径”，而非通用的视觉特征，从而导致过拟合。为此，我们引入了一系列数据增强策略：
```python
transform_train = transforms.Compose(
[
	transforms.RandomCrop(32, padding=4, padding_mode="reflect"),# 随机裁剪
	transforms.RandomHorizontalFlip(),# 随机水平翻转
	transforms.RandomApply(
		[
			transforms.ColorJitter(
				brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1
			)# 调整图像的亮度、对比度、饱和度和色调
		],
		p=0.3,
	),# 以一定概率 p 应用一组变换
	transforms.RandomRotation(10),# 随机旋转
	transforms.ToTensor(),
	transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
	transforms.RandomErasing(p=0.15, scale=(0.02, 0.2), ratio=(0.3, 3.3)),
]# 随机擦除
)
```

#### **2.2 模型结构**
我使用的模型是一个MLP。其基本结构如下：

`Input(3072) -> [Linear -> BatchNorm -> Activation -> Dropout] -> ... (重复N次) -> Linear(10) -> Softmax`

其中，隐藏层的数量（深度）、每层的神经元数量（宽度）、激活函数、Dropout率和是否使用批量归一化（BatchNorm）都是我实验中探索的超参数。

#### **2.3 评价指标**
*   **主要指标**: **Accuracy**。衡量模型在给定数据集上正确分类的样本比例，根本任务。
*   **辅助指标**: **Loss**。判断模型是否有效收敛以及是否存在过拟合。

#### **2.4 实验环境与超参数**
*   **硬件**: 4 x NVIDIA RTX 3090
*   这里我使用Weights & Biases的Bayes Sweep进行日志记录和自动化超参数搜索实验。主要探索的超参数空间如下：
    *   **`hidden_sizes`**: `[1024,512,256]`, `[512,256,128]`, `[1024,512]`, `[1024,1024,512]`, `[512,1024,512]`, `[1024,1024]`, `[2048,512]`
    *   **`loss_function`**: `cross_entropy`, `focal_loss`
    *   **`optimizer`**: `adamw`, `sgd`
    *   **`scheduler`**: `plateau`, `cosine`,`cosine_wr`, `onecycle`
    *   **`learning_rate`**: `log_uniform(1e-4, 1e-3)`
    *   **`dropout`**: `uniform(0.3, 0.5)`
    *   **`weight_decay`**: `log_uniform(1e-5, 5e-4)`
*   **固定参数**:
    *   **`batch_size`**: 256

---

### **3. 实验结果与分析**
值得一提的是，在调参过程中，我发现深度学习模型的超参数其实是相互影响、相互依赖的，而不是孤立的。

比如说，一个对于 AdamW 优化器来说很完美的学习率，如果直接用在 SGD 优化器上，效果可能会非常差。

所以，虽然下面的章节为了清晰起见，会把网络架构、损失函数与正则化、优化算法等因素分开来独立讨论，但我们最终的目标是找到这些参数的最佳组合，而不是单个的万金油最佳值。这也正是我们采用 wandb 的Bayes Sweep来进行自动化实验的原因——它能够帮助我们在这样一个复杂的多维空间中，更智能地寻找全局最优的超参数配置。

同时，为了更有效率的探索，我开启了hyperband早停策略，并不是每个超参组合都会运行到最后。

#### **3.1 网络架构的影响**
**过滤器设置：** scheduler=cosine、optimizer IN adam or adamw
![[Pic/Pasted image 20251102113730.png]]
**结果分析：** 从图中可以看出，在训练效果上，`[1024,1024,512]`>[2048,512]≈[1024,1024]≈[512,1024,512]>[1024,512,256]>[1024,512]>>[512,256,128]
这一结果揭示了几个关键点：
1. [2048,512]效果优于[1024,512]，即为了从3072维的扁平化像素中有效提取丰富的初始特征，一个足够“宽”的入口是必要的。较窄的入口（如512）可能会在第一步就造成信息瓶颈，限制了模型的学习上限。
2.  三层的 [1024, 1024, 512]、[512,1024,512] 表现均优于双层网络 [1024, 512]，说明在有足够宽度的情况下，增加深度可以帮助模型学习更具层次性的抽象特征。

---

#### **3.2 损失函数与正则化方法分析 (附加题1)**
**过滤器设置：** scheduler=cosine、optimizer IN adam or adamw
**实验目的**: 对比不同损失函数的效果，并分析正则化策略对抑制过拟合的作用。

**3.2.1 损失函数对比**
注：这里label_smoothing和cross_entropy曲线应该合并，因为我疏忽没有修改label_smoothing 参数默认值0，其执行的是标准的交叉熵计算。
![[Pic/Pasted image 20251102114047.png]]
**结果分析**:
cross_entropy的性能显著优于focal_loss。这符合我们的预期，因为Focal Loss主要设计用于解决**类别不均衡**问题，而CIFAR-10是一个完全类别均衡的数据集（每个类别各6000张图片），因此Focal Loss的核心优势无法发挥。

**3.2.2 正则化效果分析**

![[Pic/Pasted image 20251102114319.png]]

**结果分析**:
当我筛选Val/Accuracy≥60%的结果时，有一个非常清晰的趋势就是dropout率集中在[0.3,0.45]区间内。低于0.3，正则化不足，模型容易过拟合；高于0.5，则可能导致欠拟合，模型无法充分学习。
与此同时，weight_decay（L2正则化）的取值在 (1e-5, 5e-4) 范围内分布较为均匀，没有显示出强烈的偏好。这表明，虽然权重衰减有一定作用，但在本次实验中，Dropout是抑制过拟合、提升泛化能力的主导因素。

---

#### **3.3 优化算法分析 (附加题2)**

**实验目的**: 比较不同优化器和学习率调度器对模型收敛速度和最终性能的影响。
**optimizer的对比：**
![[Pic/Pasted image 20251102115313.png]]
**结果分析**:
1. Adam和AdamW这两种自适应学习率优化器展现了压倒性的收敛速度优势。从图中可见，它们在最初的几千步内就迅速将准确率提升到较高水平。相比之下，传统的SGD（即使配合了动量）收敛速度要慢得多，尤其在训练初期。
2. AdamW效果不如Adam。

**scheduler的对比：**
![[Pic/Pasted image 20251102115630.png]]

**结果分析**:


---

### **4. 最佳模型与性能评估**
通过对所有实验运行的分析，我从W&B中筛选出在验证集上准确率最高的模型。其超参数配置如下：

| 超参数             | 最佳值                      |
| :-------------- | :----------------------- |
| `batch_size`    | `256`                    |
| `hidden_sizes`  | `1024, 1024, 512`        |
| `loss_function` | `cross_entropy`          |
| `optimizer`     | `adam`                   |
| `scheduler`     | `cosine`                 |
| `learning_rate` | `0.0006615675670086777`  |
| `dropout`       | `0.30294330102777184`    |
| `weight_decay`  | `0.00008469219252212608` |
| **验证集最高准确率**    | **70.78%**               |
| **测试集准确率**      | **70.16%**               |
![[Pic/Pasted image 20251102121530.png]]

**结果分析**:
混淆矩阵直观地展示了模型在各个类别上的性能。从图中可以看出，模型在airplane(754/1000), automobile(805/1000), ship(805/1000) 和 horse(785/1000) 等轮廓鲜明、特征独特的类别上表现出色，正确率很高。
最主要的混淆发生在视觉特征相似的类别之间。例如，有204个cat被错误地识别为了dog，同时有169个dog被错认为deer。同样，大量的truck(111个)被错分为automobile。
这种混淆模式暴露了全连接网络的根本弱点：它将图像展平为一维向量，完全忽略了像素之间的空间结构信息。因此，它难以学习到纹理、形状等对区分猫狗至关重要的局部空间特征。

**定性结果：**
![[Pic/Pasted image 20251102121536.png]]

---

### **5. 结论与展望**

#### **5.1 结论总结**
本次实验成功地构建了一个用于CIFAR-10分类的全连接神经网络。我通过系统的超参数调优，发现：
1.  `1024,1024,512`是处理此任务的有效架构。
2.  正则化（特别是Dropout和标签平滑）对于防止过拟合、提升模型泛化能力至关重要。
3.  `Adam`优化器与`Cosine`学习率调度器的组合，在收敛速度和最终性能上都表现出色。

我的最佳模型最终在测试集上取得了 **70.16%** 的准确率，完成了本次作业的任务。

#### **5.2 思考与展望**
尽管全连接网络能够完成分类任务，但其性能存在瓶颈，主要因为它忽略了图像的空间结构信息。未来的改进方向可以包括：
1.  使用CNN: CNN专门为处理网格状数据（如图像）而设计，其卷积核能够有效提取局部空间特征，在图像分类任务上通常远胜于FCN。
2.  更先进的架构: 尝试引入残差连接（ResNet）等更现代的神经网络结构，以训练更深、性能更强的模型。