现在损失函数('/mnt/sdb/chenmohan/VGGT-NBV/nbv_framework/training/losses.py')计算ChamferDistance时候需要先对pred_pointclouds和gt_pointclouds进行ICP对齐，然而其效果并不是很好，基本不可用。现在，我希望你能将其修改成Umeyama算法进行对齐。

具体来说是因为每一个pred_pointclouds中的点都一一对应input_images上面的点，进而一一对应gt_mesh(mesh = gt_mesh_data['normalized_mesh']'/mnt/sdb/chenmohan/VGGT-NBV/nbv_framework/datasets/house3k_dataset.py')的上面三维坐标(虽然这个点不一定在gt_mesh_data["gt_points"]中，因为其是在'/mnt/sdb/chenmohan/VGGT-NBV/nbv_framework/utils/mesh_utils.py'里面sampled_points = sample_points_from_meshes(normalized_mesh, num_samples=num_samples)这么采样出来的，你需要仔细思考解决这个问题)。前者对应是vggt直接输出的，后者对应是通过house3k_dataset.py中图片的渲染函数
```
rendered_images = renderer.forward(
	gt_mesh=meshes_batch,
	camera_poses=camera_poses_tensor,
	pose_format="cartesian",
	fov=60.0,
	lighting_type="ambient"
)
```
其中，render要用到'/mnt/sdb/chenmohan/VGGT-NBV/nbv_framework/rendering/differentiable_renderer.py'这个类。

注意：你需要去找原始的绝对正确的一一对应关系，而不是通过让预测点云的每个点用 knn_points(..., K=1) 在GT点云中找最近邻，得到一一的最近邻匹配，这是没有任何意义的，还是得不好正确的CDloss。

请你仔细思考我这个修改方案，先评估可行性，告诉我你想要修改的文件。